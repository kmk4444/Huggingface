{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOShiQVJ4o6DKbApHpXnnk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Huggingface/blob/main/Automatic_speech_recognition_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 6: Automatic Speech Recognition"
      ],
      "metadata": {
        "id": "cRAuvP42jTMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the classroom, the libraries are already installed for you.\n",
        "- If you would like to run this code on your own machine, you can install the following:\n",
        "```\n",
        "    !pip install transformers\n",
        "    !pip install -U datasets\n",
        "    !pip install soundfile\n",
        "    !pip install librosa\n",
        "    !pip install gradio\n",
        "```\n",
        "\n",
        "The `librosa` library may need to have [ffmpeg](https://www.ffmpeg.org/download.html) installed.\n",
        "- This page on [librosa](https://pypi.org/project/librosa/) provides installation instructions for ffmpeg."
      ],
      "metadata": {
        "id": "wFThysb6jbDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FhQZURoitV3"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install -U datasets\n",
        "!pip install soundfile\n",
        "!pip install librosa\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "JPQWaRNCmiW7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation"
      ],
      "metadata": {
        "id": "I2AW3hflms5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "HZkXmD0nmuBx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"librispeech_asr\",\n",
        "                       split=\"train.clean.100\",\n",
        "                       streaming=True,\n",
        "                       trust_remote_code=True)"
      ],
      "metadata": {
        "id": "v6-q-o7Zmwcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = next(iter(dataset))"
      ],
      "metadata": {
        "id": "EoR1Z73Fm4NO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_head = dataset.take(5)\n",
        "list(dataset_head)"
      ],
      "metadata": {
        "id": "TfFZHhDwnCua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dataset_head)[2]"
      ],
      "metadata": {
        "id": "g7uBTDBUwGsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example"
      ],
      "metadata": {
        "id": "v55RC-W0wLw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio as IPythonAudio\n",
        "\n",
        "IPythonAudio(example[\"audio\"][\"array\"],\n",
        "             rate=example[\"audio\"][\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "ko69NDUEwNqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the pipeline"
      ],
      "metadata": {
        "id": "MHcw-XJCwcoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "OfafWvIjwdQW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr = pipeline(task=\"automatic-speech-recognition\",\n",
        "               model=\"distil-whisper/distil-small.en\")"
      ],
      "metadata": {
        "id": "NdovalqWxQKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Info about [distil-whisper/distil-small.en](https://huggingface.co/distil-whisper)"
      ],
      "metadata": {
        "id": "JHgn2IzPxVhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asr.feature_extractor.sampling_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG5Wrj97xZPR",
        "outputId": "fca44fd8-48f6-43fa-d150-dd463ba988fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"audio\"][\"sampling_rate\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0NnDk7Sxc-7",
        "outputId": "1c827116-5417-4c52-9c19-725a39633f2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6PLgnAQxhau",
        "outputId": "3882bd12-285f-4ed4-c266-72053f599c94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' Chapter 16 I might have told you of the beginning of this liaison in a few lines, but I wanted you to see every step by which we came. I too agree to whatever Marguerite wished.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lIrgeGKuxlPA",
        "outputId": "1bada980-d484-4298-ceaf-a12b3c91fe9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CHAPTER SIXTEEN I MIGHT HAVE TOLD YOU OF THE BEGINNING OF THIS LIAISON IN A FEW LINES BUT I WANTED YOU TO SEE EVERY STEP BY WHICH WE CAME I TO AGREE TO WHATEVER MARGUERITE WISHED'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a shareable app with Gradio\n",
        "\n",
        "### Troubleshooting Tip\n",
        "- Note, in the classroom, you may see the code for creating the Gradio app run indefinitely.\n",
        "  - This is specific to this classroom environment when it's serving many learners at once, and you won't wouldn't experience this issue if you run this code on your own machine.\n",
        "- To fix this, please restart the kernel (Menu Kernel->Restart Kernel) and re-run the code in the lab from the beginning of the lesson."
      ],
      "metadata": {
        "id": "ev_1IdXixp8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "VJUH26RHxrB9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Blocks()"
      ],
      "metadata": {
        "id": "wXSgETDVxvQB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_speech(filepath):\n",
        "    if filepath is None:\n",
        "        gr.Warning(\"No audio found, please retry.\")\n",
        "        return \"\"\n",
        "    output = asr(filepath)\n",
        "    return output[\"text\"]"
      ],
      "metadata": {
        "id": "IX6jmcP3xyBI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mic_transcribe = gr.Interface(\n",
        "    fn=transcribe_speech,\n",
        "    inputs=gr.Audio(sources=\"microphone\",\n",
        "                    type=\"filepath\"),\n",
        "    outputs=gr.Textbox(label=\"Transcription\",\n",
        "                       lines=3),\n",
        "    allow_flagging=\"never\")"
      ],
      "metadata": {
        "id": "ACs5SJq5x3pU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To learn more about building apps with Gradio, you can check out the short course: [Building Generative AI Applications with Gradio](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/), also taught by Hugging Face."
      ],
      "metadata": {
        "id": "HHUlQTb3x8qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_transcribe = gr.Interface(\n",
        "    fn=transcribe_speech,\n",
        "    inputs=gr.Audio(sources=\"upload\",\n",
        "                    type=\"filepath\"),\n",
        "    outputs=gr.Textbox(label=\"Transcription\",\n",
        "                       lines=3),\n",
        "    allow_flagging=\"never\",\n",
        ")"
      ],
      "metadata": {
        "id": "axp-vJ3vx9JW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with demo:\n",
        "    gr.TabbedInterface(\n",
        "        [mic_transcribe,\n",
        "         file_transcribe],\n",
        "        [\"Transcribe Microphone\",\n",
        "         \"Transcribe Audio File\"],\n",
        "    )\n",
        "\n",
        "demo.launch(share=True,\n",
        "            server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "IEYp6oyByLsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "9BH5GMrayQva"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note: Please stop the demo before continuing with the rest of the lab.\n",
        "- The app will continue running unless you run\n",
        "  ```Python\n",
        "  demo.close()\n",
        "  ```\n",
        "- If you run another gradio app (later in this lesson) without first closing this appp, you'll see an error message:\n",
        "  ```Python\n",
        "  OSError: Cannot find empty port in range\n",
        "  ```"
      ],
      "metadata": {
        "id": "6ho2_WSNydaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Testing with a longer audio file"
      ],
      "metadata": {
        "id": "wOwKLQtRyfHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sampling_rate = sf.read('narration_example.wav')"
      ],
      "metadata": {
        "id": "y_6Udymiyj3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_rate"
      ],
      "metadata": {
        "id": "ZdsqF3sOykmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr.feature_extractor.sampling_rate"
      ],
      "metadata": {
        "id": "a07Su3FSylhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr(audio)"
      ],
      "metadata": {
        "id": "9uM34YqGymJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Note:_ Running the cell above will return:\n",
        "```\n",
        "ValueError: We expect a single channel audio input for AutomaticSpeechRecognitionPipeline\n",
        "```\n"
      ],
      "metadata": {
        "id": "EYX4cCRwym7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Convert the audio from stereo to mono (Using librosa)"
      ],
      "metadata": {
        "id": "cA0iIvoGyoBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio.shape"
      ],
      "metadata": {
        "id": "49hVlsHsyou0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "audio_transposed = np.transpose(audio)"
      ],
      "metadata": {
        "id": "sOBHahyVypZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_transposed.shape"
      ],
      "metadata": {
        "id": "gliohQHNyqMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "id": "cSrXzadHyrHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_mono = librosa.to_mono(audio_transposed)"
      ],
      "metadata": {
        "id": "_aASg1MMyrw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPythonAudio(audio_mono,\n",
        "             rate=sampling_rate)"
      ],
      "metadata": {
        "id": "bFPvNMsxysYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr(audio_mono)"
      ],
      "metadata": {
        "id": "2Rn5uxTnytFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Warning:_ The cell above might throw a warning because the sample rate of the audio sample is not the same of the sample rate of the model.\n",
        "\n",
        "Let's check and fix this!"
      ],
      "metadata": {
        "id": "n-0J5FHryvXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_rate"
      ],
      "metadata": {
        "id": "kFIC1zzqywPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr.feature_extractor.sampling_rate"
      ],
      "metadata": {
        "id": "R21_PENQyxGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_16KHz = librosa.resample(audio_mono,\n",
        "                               orig_sr=sampling_rate,\n",
        "                               target_sr=16000)"
      ],
      "metadata": {
        "id": "rkI7afwWyx2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr(\n",
        "    audio_16KHz,\n",
        "    chunk_length_s=30, # 30 seconds\n",
        "    batch_size=4,\n",
        "    return_timestamps=True,\n",
        ")[\"chunks\"]"
      ],
      "metadata": {
        "id": "kDDxBMWcyyn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Build the Gradio interface."
      ],
      "metadata": {
        "id": "w0P-3l5_yzh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "demo = gr.Blocks()"
      ],
      "metadata": {
        "id": "7y_Aw3hDy0M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_long_form(filepath):\n",
        "    if filepath is None:\n",
        "        gr.Warning(\"No audio found, please retry.\")\n",
        "        return \"\"\n",
        "    output = asr(\n",
        "      filepath,\n",
        "      max_new_tokens=256,\n",
        "      chunk_length_s=30,\n",
        "      batch_size=8,\n",
        "    )\n",
        "    return output[\"text\"]"
      ],
      "metadata": {
        "id": "WgexaCrQy0_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mic_transcribe = gr.Interface(\n",
        "    fn=transcribe_long_form,\n",
        "    inputs=gr.Audio(sources=\"microphone\",\n",
        "                    type=\"filepath\"),\n",
        "    outputs=gr.Textbox(label=\"Transcription\",\n",
        "                       lines=3),\n",
        "    allow_flagging=\"never\")\n",
        "\n",
        "file_transcribe = gr.Interface(\n",
        "    fn=transcribe_long_form,\n",
        "    inputs=gr.Audio(sources=\"upload\",\n",
        "                    type=\"filepath\"),\n",
        "    outputs=gr.Textbox(label=\"Transcription\",\n",
        "                       lines=3),\n",
        "    allow_flagging=\"never\",\n",
        ")"
      ],
      "metadata": {
        "id": "NHJLs4rCy1wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with demo:\n",
        "    gr.TabbedInterface(\n",
        "        [mic_transcribe,\n",
        "         file_transcribe],\n",
        "        [\"Transcribe Microphone\",\n",
        "         \"Transcribe Audio File\"],\n",
        "    )\n",
        "demo.launch(share=True,\n",
        "            server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "fIRtpWJmy2lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "EF3tCE2gy3dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note: Please stop the demo before continuing with the rest of the lab.\n",
        "- The app will continue running unless you run\n",
        "  ```Python\n",
        "  demo.close()\n",
        "  ```\n",
        "- If you run another gradio app (later in this lesson) without first closing this appp, you'll see an error message:\n",
        "  ```Python\n",
        "  OSError: Cannot find empty port in range\n",
        "  ```"
      ],
      "metadata": {
        "id": "5s54VuA8y4oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try it yourself!\n",
        "- Try this model with your own audio files!"
      ],
      "metadata": {
        "id": "b0qDnaQTy5qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import io\n",
        "\n",
        "audio, sampling_rate = sf.read('narration_example.wav')"
      ],
      "metadata": {
        "id": "Fqvwdo0ky6Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_rate"
      ],
      "metadata": {
        "id": "uoSlpN5cy7BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr.feature_extractor.sampling_rate"
      ],
      "metadata": {
        "id": "VEequ_IDy7ur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}